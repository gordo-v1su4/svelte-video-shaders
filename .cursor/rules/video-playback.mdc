---
description: Video playback best practices using WebCodecs, mp4box, and three.js for svelte-video-shaders
globs:
alwaysApply: true
---
# Video Playback Best Practices

This rule covers video playback implementation using WebCodecs, mp4box, and three.js integration. Based on the current [ShaderPlayer.svelte](mdc:src/lib/ShaderPlayer.svelte) and [frame-buffer.js](mdc:src/lib/frame-buffer.js) implementations.

## Core Video Playback Architecture

### Technology Stack
- **WebCodecs API**: Native browser video decoding (Chrome 94+, Edge 94+, Safari 16.4+)
- **mp4box.js**: MP4 container demuxing and sample extraction (requires Vite optimizeDeps exclusion)
- **Frame Buffer**: Pre-decoded ImageBitmap arrays for seamless retiming (GPU-resident for WebGL)
- **three.js**: WebGL2 rendering with shader materials
- **Audio-reactive**: Real-time FFT drives shader uniforms and playback speed
- **SvelteKit**: SSR-safe implementation with onMount gating

### Import Pattern
```javascript
// ✅ Correct: mp4box import for Vite compatibility
import { default as MP4BoxModule } from 'mp4box';

// ✅ Alternative: namespace import
import * as MP4Box from 'mp4box';
```

## WebCodecs + mp4box Pipeline

### 1. MP4Box Setup
```javascript
// ✅ Good: Create MP4Box file instance
mp4boxfile = MP4BoxModule.createFile();

// ✅ Good: Handle ready event for decoder configuration
mp4boxfile.onReady = (info) => {
  const track = info.videoTracks[0];
  if (VideoDecoder.isConfigSupported(track.codec)) {
    videoDecoder.configure({
      codec: track.codec,
      codedWidth: track.track_width,
      codedHeight: track.track_height
    });
    mp4boxfile.setExtractionOptions(track.id, null, { nbSamples: 100 });
    mp4boxfile.start();
  }
};

// ✅ Good: Handle samples for decoder feeding
mp4boxfile.onSamples = (track_id, ref, samples) => {
  for (const sample of samples) {
    const type = sample.is_sync ? 'key' : 'delta';
    const chunk = new EncodedVideoChunk({
      type,
      timestamp: sample.cts,
      duration: sample.duration,
      data: sample.data
    });
    if (videoDecoder.state === 'configured') {
      videoDecoder.decode(chunk);
    }
  }
};
```

### 2. VideoDecoder Configuration
```javascript
// ✅ Good: Create decoder with proper error handling
videoDecoder = new VideoDecoder({
  output: (frame) => {
    // Handle decoded frame
    onVideoFrame(frame);
  },
  error: (e) => console.error('[Decoder]', e)
});

// ✅ Good: Check codec support before configuring
if (VideoDecoder.isConfigSupported(track.codec)) {
  videoDecoder.configure({
    codec: track.codec,
    codedWidth: track.track_width,
    codedHeight: track.track_height
  });
}
```

### 3. Frame Processing with ImageBitmap

**Current Implementation:** VideoFrames are converted to ImageBitmaps for persistent storage:

```javascript
// ✅ Good: Convert VideoFrame to ImageBitmap, then close VideoFrame immediately
const videoDecoder = new VideoDecoder({
  output: (frame) => {
    // Create ImageBitmap copy (GPU-resident for WebGL)
    createImageBitmap(frame).then(bitmap => {
      // Store ImageBitmap in frame buffer
      frames.push(bitmap);
      onProgress(frames.length / totalSamples);
    }).catch(e => {
      console.error('Failed to create ImageBitmap:', e);
    }).finally(() => {
      // ✅ CRITICAL: Always close VideoFrame immediately to free decoder buffers
      frame.close();
    });
  },
  error: (e) => console.error('[Decoder]', e)
});
```

**Using ImageBitmap in Three.js:**

```javascript
// ✅ Good: Update three.js texture with ImageBitmap from frame buffer
function render() {
  const bitmap = frameBuffer.getFrame(globalFrameIndex);
  if (bitmap && texture) {
    texture.image = bitmap; // ImageBitmap works directly with Three.js textures
    texture.needsUpdate = true;
  }
  renderer.render(scene, camera);
}
```

**Why ImageBitmap?**
- GPU-resident (stays on GPU for WebGL textures)
- Persistent (can be stored in arrays for random access)
- VideoFrame must be closed immediately, ImageBitmap can live longer

## Three.js Integration

### 1. Camera Setup
```javascript
// ✅ Good: Use OrthographicCamera for 2D video planes
camera = new THREE.OrthographicCamera(-1, 1, 1, -1, 0.1, 10);

// ✅ Good: Responsive camera sizing
function handleResize() {
  if (!renderer || !camera || !canvas) return;
  const width = canvas.clientWidth;
  const height = canvas.clientHeight;
  renderer.setSize(width, height);
  camera.left = -width / 2;
  camera.right = width / 2;
  camera.top = height / 2;
  camera.bottom = -height / 2;
  camera.updateProjectionMatrix();
}
```

### 2. Shader Material
```javascript
// ✅ Good: Shader material with texture uniform
const material = new THREE.ShaderMaterial({
  vertexShader,
  fragmentShader,
  uniforms: {
    ...uniforms,
    u_texture: { value: new THREE.Texture() }
  },
  transparent: true
});
```

### 3. Render Loop
```javascript
// ✅ Good: Separate render loop from decoding
function animate() {
  animationFrameId = requestAnimationFrame(animate);
  renderer.render(scene, camera);
}
```

## Video Loading & Streaming

### 1. Fetch with Streaming
```javascript
// ✅ Good: Stream video data to MP4Box
const response = await fetch(src);
if (!response.ok) {
  throw new Error(`Failed to fetch video: ${response.statusText}`);
}

const reader = response.body.getReader();
let offset = 0;

while (true) {
  const { done, value } = await reader.read();
  if (done) {
    mp4boxfile.flush();
    break;
  }
  const buffer = value.buffer;
  buffer.fileStart = offset;
  offset += buffer.byteLength;
  mp4boxfile.appendBuffer(buffer);
}
```

### 2. Error Handling
```javascript
// ✅ Good: Comprehensive error handling
try {
  // Video loading logic
} catch (e) {
  console.error('[Player] FATAL: Failed to start WebCodecs pipeline:', e);
  // Fallback to HTML5 video or show error
}
```

## Fallback Strategy

### 1. Browser Support Detection
```javascript
// ✅ Good: Check WebCodecs support
if (!window.VideoDecoder || !window.MP4Box) {
  console.warn('⚠️ WebCodecs not supported, using fallback');
  useFallback = true;
  return;
}
```

### 2. HTML5 Video Fallback
```svelte
<!-- ✅ Good: Conditional rendering -->
{#if useFallback}
  <video
    bind:this={fallbackVideo}
    src={src}
    class="fallback-video"
    muted
    loop
    preload="auto"
    crossorigin="anonymous"
  ></video>
{:else}
  <canvas bind:this={canvas} class="webgl-canvas"></canvas>
{/if}
```

## Memory Management

### 1. Resource Cleanup (SvelteKit onMount)

```javascript
// ✅ Good: Proper cleanup in onMount return function (SvelteKit pattern)
import { onMount } from 'svelte';

onMount(() => {
  // Initialize WebCodecs decoder (browser-only)
  const videoDecoder = new VideoDecoder({ ... });
  
  // Setup render loop
  function render() { ... }
  render();
  
  // Cleanup function returned from onMount
  return () => {
    cancelAnimationFrame(animationFrameId);
    if (renderer) renderer.dispose();
    if (texture) texture.dispose();
    if (videoDecoder && videoDecoder.state !== 'closed') {
      videoDecoder.close();
    }
    if (mp4boxfile) mp4boxfile.stop();
  };
});
```

### 2. ImageBitmap Management

```javascript
// ✅ Good: ImageBitmap cleanup in frame buffer dispose
dispose() {
  // Close all ImageBitmaps to free GPU memory
  for (const [_, frames] of this.clips) {
    for (const frame of frames) {
      if (frame && typeof frame.close === 'function') {
        frame.close(); // ImageBitmap.close() frees GPU memory
      }
    }
  }
  this.clips.clear();
}
```

**Note:** VideoFrames are closed immediately after ImageBitmap conversion during decoding. ImageBitmaps are closed when the frame buffer is disposed.

## Performance Optimizations

### 1. Sample Buffering
```javascript
// ✅ Good: Buffer samples for smooth playback
mp4boxfile.setExtractionOptions(track.id, null, { nbSamples: 100 });
```

### 2. Render Loop Optimization
```javascript
// ✅ Good: Separate render loop from decoding
// Decoding happens in onSamples callback
// Rendering happens in requestAnimationFrame
```

### 3. Texture Updates
```javascript
// ✅ Good: Only update texture when needed
if (mesh && mesh.material.uniforms.u_texture.value) {
  mesh.material.uniforms.u_texture.value.image = frame;
  mesh.material.uniforms.u_texture.value.needsUpdate = true;
}
```

## Browser Compatibility

### Supported Browsers
- **Chrome 94+**: Full WebCodecs support
- **Edge 94+**: Full WebCodecs support  
- **Safari 16.4+**: Full WebCodecs support
- **Firefox**: No WebCodecs support (use fallback)

### Testing Checklist
- [ ] Test WebCodecs pipeline in Chrome/Edge/Safari
- [ ] Test HTML5 video fallback in Firefox
- [ ] Verify memory usage doesn't grow over time
- [ ] Check performance with different video sizes
- [ ] Test error handling for corrupted videos

## Common Issues & Solutions

### 1. MP4Box Import Issues
```javascript
// ❌ Bad: Direct import may fail in Vite
import MP4Box from 'mp4box';

// ✅ Good: Use default import for Vite compatibility
import { default as MP4BoxModule } from 'mp4box';
```

### 2. VideoFrame Memory Leaks
```javascript
// ❌ Bad: Forgetting to close VideoFrame
function onVideoFrame(frame) {
  texture.image = frame;
  texture.needsUpdate = true;
  // Missing: frame.close()
}

// ✅ Good: Always close VideoFrame
function onVideoFrame(frame) {
  texture.image = frame;
  texture.needsUpdate = true;
  frame.close(); // ✅ Required
}
```

### 3. Camera Sizing Issues
```javascript
// ❌ Bad: Using PerspectiveCamera for 2D video
camera = new THREE.PerspectiveCamera(75, width / height, 0.1, 1000);

// ✅ Good: Use OrthographicCamera for 2D
camera = new THREE.OrthographicCamera(-width/2, width/2, height/2, -height/2, 0.1, 10);
```

## Pre-Decoded Frame Buffer System

For seamless retiming, speed ramps, and jump cuts, use the pre-decoded frame buffer approach:

### 1. Frame Buffer Setup (WebCodecs with ImageBitmap)

```javascript
import { WebCodecsFrameBuffer } from '$lib/webcodecs-frame-buffer.js';

// Create frame buffer instance
const frameBuffer = new WebCodecsFrameBuffer({ targetFps: 24 });

// Pre-decode all videos with progress callback
// VideoFrames are converted to ImageBitmaps and stored
await frameBuffer.preloadClips(videoFiles, (progress, status) => {
  console.log(`${status}: ${(progress * 100).toFixed(0)}%`);
});

console.log(`Ready: ${frameBuffer.totalFrames} frames`);
console.log(`Output dimensions: ${frameBuffer.outputWidth}x${frameBuffer.outputHeight}`);
```

### 2. Frame Access (ImageBitmap)

```javascript
// ✅ Good: Random access to any frame (returns ImageBitmap)
const bitmap = frameBuffer.getFrame(globalFrameIndex);
const localBitmap = frameBuffer.getFrameAt(clipIndex, localFrameIndex);

// ImageBitmap can be used directly with Three.js textures
if (bitmap) {
  texture.image = bitmap;
  texture.needsUpdate = true;
}
```

### 3. ShaderPlayer Integration
```svelte
<ShaderPlayer
  bind:this={shaderPlayerRef}
  {frameBuffer}
  {uniforms}
  {fragmentShader}
  onVideoEnd={handleVideoEnd}
/>

<script>
  // Control playback
  shaderPlayerRef.play();
  shaderPlayerRef.pause();
  shaderPlayerRef.seek(frameIndex);
  shaderPlayerRef.setSpeed(1.5);
  shaderPlayerRef.jumpFrames(30); // Jump forward 30 frames
</script>
```

## Audio-Reactive Playback

### Real-time FFT Analysis
```javascript
import { AudioAnalyzer } from '$lib/audio-utils.js';

const audioAnalyzer = new AudioAnalyzer();
await audioAnalyzer.initializeAudio(audioFile);

function updateLoop() {
  const audioData = audioAnalyzer.getAudioData();
  // audioData: { audioLevel, bassLevel, midLevel, trebleLevel }
  
  // Update shader uniforms
  uniforms.u_audioLevel.value = audioData.audioLevel;
  uniforms.u_bassLevel.value = audioData.bassLevel;
  
  requestAnimationFrame(updateLoop);
}
```

### Beat-Synced Video Control
```javascript
// Offline beat detection via Python API
import { EssentiaService } from '$lib/essentia-service.js';

const essentiaService = new EssentiaService();
await essentiaService.initialize();
const { bpm, beats } = await essentiaService.analyzeFile(audioFile);

// Sync video to beats
if (bassLevel > beatSensitivity) {
  shaderPlayerRef.jumpFrames(Math.random() * 60); // Random jump cut
}
```

## Timeline Component Integration

### WaveformDisplay Usage
```svelte
<WaveformDisplay
  {audioFile}
  beats={analysisData.beats}
  bpm={analysisData.bpm}
  currentTime={audioCurrentTime}
  duration={audioDuration}
  frameRate={30}
  onSeek={(time) => audioAnalyzer.seekTo(time)}
  onSegmentChange={(segments) => handleSegments(segments)}
  onMarkerAdd={(marker) => handleMarker(marker)}
/>
```

### Timeline Features
- **Time display modes**: Time (mm:ss.ms), Frames, Beats
- **Zoomable**: Ctrl+scroll to zoom, scroll to pan
- **Segments**: Shift+drag to create, drag handles to resize
- **Markers**: Press M to add marker at playhead
- **Snap to beats**: Toggle for beat-aligned editing

## Vite Configuration

### Required: mp4box Exclusion

**Critical:** mp4box must be excluded from Vite's dependency optimization:

```javascript
// vite.config.js
export default defineConfig({
  optimizeDeps: {
    exclude: ['mp4box'] // Prevent Vite from pre-bundling (required for ESM compatibility)
  },
  // ... rest of config
});
```

**Why?** mp4box uses ESM and requires raw module loading. Vite's pre-bundling can cause resolution errors or HMR issues.

## SvelteKit SSR Patterns

### All WebCodecs Code Must Be in onMount

```javascript
// ✅ Correct: WebCodecs in onMount (browser-only)
import { onMount } from 'svelte';

onMount(() => {
  // Safe to use WebCodecs APIs here
  if (typeof window !== 'undefined' && window.VideoDecoder) {
    const decoder = new VideoDecoder({ ... });
    // ... setup code
  }
  
  return () => {
    // Cleanup
  };
});

// ❌ Incorrect: WebCodecs at top level breaks SSR
const decoder = new VideoDecoder({ ... }); // Error: window is not defined
```

## References
- [ShaderPlayer.svelte](mdc:src/lib/ShaderPlayer.svelte)
- [webcodecs-frame-buffer.js](mdc:src/lib/webcodecs-frame-buffer.js) - WebCodecs + ImageBitmap implementation
- [WaveformDisplay.svelte](mdc:src/lib/WaveformDisplay.svelte)
- [audio-utils.js](mdc:src/lib/audio-utils.js)
- [essentia-service.js](mdc:src/lib/essentia-service.js)
- [webcodecs-api.mdc](mdc:.cursor/rules/webcodecs-api.mdc) - WebCodecs API best practices
- [stack-and-dependencies.mdc](mdc:.cursor/rules/stack-and-dependencies.mdc)
